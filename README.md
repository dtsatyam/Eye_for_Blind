# Eye for Blind
> Create a deep learning model which can explain the contents of an image in the form of speech through caption generation with an attention mechanism

## Table of Contents
* [General Info](#general-information)
* [Technologies Used](#technologies-used)
* [Acknowledgements](#acknowledgements)

<!-- You can include any other section that is pertinent to your problem -->

## General Information
### Analysis Methodology
1. Read the data
2. Pre-process the captions
3. Pre-process the images
4. Use ImageNet for model
5. Dataset creation and model building
6. Model building

<!-- You don't have to answer all the questions - just the ones relevant to your project. -->

<!-- You don't have to answer all the questions - just the ones relevant to your project. -->


## Technologies Used
- numpy - 1.21.5
- pandas - 1.4.2
- matplotlib - 3.5.1
- seaborn - 0.11.2
- python - 3.7
- tensorflow

<!-- As the libraries versions keep on changing, it is recommended to mention the version of library used in this project -->

## Acknowledgements
Thanks to
- https://www.geeksforgeeks.org/
- https://pandas.pydata.org/
- https://seaborn.pydata.org/
- https://stackoverflow.com/


## Contributor
Created by 
- Satyanaraya D
> [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/dtsatyam) 

Please feel free to contact us.

<!-- Optional -->
<!-- ## License -->
<!-- This project is open source and available under the [... License](). -->

<!-- You don't have to include all sections - just the one's relevant to your project -->